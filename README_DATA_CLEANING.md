# Data Cleaning Pipeline for Austrian Comorbidity Networks

Python pipeline to transform Austrian comorbidity adjacency matrices into cleaned edge-list format, processing 82 stratified matrices across three granularity levels (ICD/Blocks/Chronic).

## Overview

This pipeline processes disease comorbidity data from 8.9M Austrian hospital patients (1997-2014) and converts stratified adjacency matrices into a clean, analysis-ready edge-list format.

## Features

- **Processes 82 stratified matrices** (sex × age/year × granularity combinations)
- **Three granularity levels**: ICD (1080 diseases), Blocks (131 groups), Chronic (46 conditions)
- **P-value extraction** from R .rds contingency tables
- **ICD chapter mapping** with German-to-English translation support
- **Statistical filtering**: odds ratio ≥ 1.5, minimum 100 patients
- **Comprehensive validation report** generation

## Installation

```bash
# Install dependencies
pip install -r requirements.txt
```

## Prerequisites

Before running the Python pipeline, you must export the contingency tables from R to CSV format. The RDS files contain complex array structures that cannot be read directly by Python.

### Step 1: Export Contingency Tables (Required)

```bash
# Run the R export script to generate CSV files
Rscript scripts/export_contingency_tables.R
```

This creates exported CSV files in `Data/Data/2.ContingencyTables/exported/` containing:
- P-values (from Mantel-Haenszel tests)
- Patient counts
- Odds ratios

For each of the 6 RDS files × 14 stratifications (6 year periods + 8 age groups).

## Usage

### Basic Usage

```bash
# Step 1: Export contingency tables (run once)
Rscript scripts/export_contingency_tables.R

# Step 2: Run Python pipeline
python scripts/run_cleaning.py
```

### Custom Options

```bash
# Custom directories
python scripts/run_cleaning.py --data-dir /path/to/data --output-dir /path/to/output

# Adjust filters
python scripts/run_cleaning.py --min-or 2.0 --min-count 200

# Enable German-to-English translation
python scripts/run_cleaning.py --translate

# Full example
python scripts/run_cleaning.py \
    --data-dir Data \
    --output-dir data/processed \
    --min-or 1.5 \
    --min-count 100 \
    --translate
```

## File Structure

```
scripts/
  data_cleaning.py          # Core processing module
  run_cleaning.py           # CLI entry point

data/
  processed/                # Output directory
    disease_pairs_clean.csv     # Main edge-list output
    disease_metadata.csv        # Disease metadata
    processing_report.txt       # Validation report

requirements.txt           # Python dependencies
```

## Input Data Structure

Required directory structure:
```
Data/
├── Data/
│   ├── 1.Prevalence/
│   │   └── Prevalence_Sex_Age_Year_ICD.csv
│   ├── 2.ContingencyTables/
│   │   ├── exported/                           # Generated by export_contingency_tables.R
│   │   │   ├── ICD_ContingencyTables_Male_year_2003-2004_pvalues.csv
│   │   │   ├── ICD_ContingencyTables_Male_year_2003-2004_counts.csv
│   │   │   ├── ICD_ContingencyTables_Male_year_2003-2004_odds_ratios.csv
│   │   │   └── ... (144 total CSV files)
│   │   ├── ICD_ContingencyTables_Male_Final.rds
│   │   ├── ICD_ContingencyTables_Female_Final.rds
│   │   ├── Blocks_ContingencyTables_Male_Final.rds
│   │   ├── Blocks_ContingencyTables_Female_Final.rds
│   │   ├── Chronic_ContingencyTables_Male_Final.rds
│   │   └── Chronic_ContingencyTables_Female_Final.rds
│   └── 3.AdjacencyMatrices/
│       ├── Adj_Matrix_Male_ICD_year_2003-2004.csv
│       ├── Adj_Matrix_Female_ICD_year_2003-2004.csv
│       ├── Adj_Matrix_Male_Blocks_age_1.csv
│       └── ... (82 total files)
├── ICD10_Diagnoses_All.csv
├── Blocks_All.csv
└── Chronic_All.csv
```

## Output Files

### 1. disease_pairs_clean.csv

Edge-list format with columns:
- `disease_1_code`, `disease_2_code`: Disease identifiers
- `disease_1_name_de`, `disease_2_name_de`: German disease names
- `disease_1_name_en`, `disease_2_name_en`: English translations (if --translate)
- `odds_ratio`: Association strength
- `p_value`: Statistical significance (from .rds files)
- `patient_count`: Number of co-occurrences
- `sex`: Male/Female
- `stratum_type`: age/year
- `stratum_value`: Age group (1-8) or year period (2003-2004, etc.)
- `granularity`: ICD/Blocks/Chronic
- `icd_chapter_1`, `icd_chapter_2`: ICD-10 chapters (I-XXI)

### 2. disease_metadata.csv

Disease metadata with columns:
- `code`: Disease identifier
- `name_de`: German name
- `name_en`: English translation
- `icd_chapter`: Chapter number
- `icd_chapter_name`: Chapter description
- `granularity`: Level of detail
- `prevalence_rate`: Aggregated prevalence from prevalence data

### 3. processing_report.txt

Comprehensive report including:
- Processing summary (matrices processed, pairs before/after filtering)
- Breakdowns by granularity, sex, and stratification type
- Odds ratio statistics (mean, median, max, min)
- ICD chapter distribution
- Unique disease counts
- Data quality metrics

## ICD-10 Translation Module (Agent 1)

Translates German ICD-10 disease descriptions to English using WHO official terminology and Google Translate fallback.

### Overview

The translation module (`scripts/translate_descriptions.py`) provides:
- **WHO-verified translations** for 113 high-prevalence ICD codes (E11, I10, I25, etc.)
- **Automated batch translation** for remaining 942 codes using Google Translate API
- **Rate-limited processing** to avoid API bans (default: 25-50 codes/batch, 0.5-1s delay)
- **Quality assurance** with verification reports and source tracking

### Usage

```bash
# Basic translation (uses default settings)
python scripts/translate_descriptions.py

# Fast translation (larger batches, shorter delays)
python scripts/translate_descriptions.py --batch-size 50 --delay 0.5

# With WHO API key (optional, for additional official translations)
python scripts/translate_descriptions.py --who-api-key YOUR_API_KEY
```

### Output Files

All files created in `Data/processed/`:

| File | Description | Size |
|------|-------------|------|
| `ICD10_Diagnoses_English.csv` | Full translations with metadata | ~141KB |
| `disease_names.csv` | Simplified mapping (code → English name) | ~58KB |
| `validation/translation_verification.txt` | Quality report with statistics | ~3KB |
| `.translation_done` | Completion marker for downstream agents | 9B |

### Translation Statistics

Typical results for 1080 ICD codes:
- **WHO verified**: ~113 codes (10.5%) - manually curated from WHO ICD-10 2019
- **Auto-translated**: ~942 codes (87.2%) - Google Translate API
- **Failed**: ~25 codes (2.3%) - empty/invalid entries preserved as German

### Security & Quality Features

- Input validation and sanitization
- Secure logging (no PHI exposure)
- Rate limiting to prevent API bans
- Graceful error handling with fallback to original German
- Comprehensive progress tracking
- Verification report generation

## Master Database Creation

After running the cleaning pipeline, create unified master databases for downstream analysis:

### Usage

```bash
# Create master databases (run after data cleaning)
python scripts/create_master_database.py

# Wait for Agent 1 translation (optional)
python scripts/create_master_database.py --wait
```

### Output Files

#### 1. diseases_master.csv

Unified disease database with columns:
- `icd_code`: Disease ICD-10 identifier
- `name_english`: English disease name (populated when translation available)
- `name_german`: German disease name
- `chapter_code`: ICD-10 chapter (I-XXI)
- `chapter_name`: Chapter description
- `granularity`: ICD/Blocks/Chronic
- `avg_prevalence_male`: Average prevalence in males (0-1)
- `avg_prevalence_female`: Average prevalence in females (0-1)

**Statistics:** 736 diseases (all with German names, prevalence data from 135,708 records)

#### 2. disease_relationships_master.csv

Aggregated relationships across all strata:
- `disease_1_code`, `disease_2_code`: Disease identifiers
- `disease_1_name`, `disease_2_name`: English disease names
- `odds_ratio_avg`: Mean odds ratio across all stratifications
- `p_value_avg`: Mean p-value across all stratifications  
- `patient_count_total`: Total patient count (sum across strata)
- `icd_chapter_1`, `icd_chapter_2`: Chapter classifications

**Statistics:** 9,232 unique relationships (aggregated from 74,901 stratified pairs)

#### 3. data_summary.json

Comprehensive summary including:
- Total counts (diseases, relationships)
- Prevalence statistics by sex
- Diseases by chapter distribution
- Most connected diseases (top 20 by relationship count)
- Strongest relationships (top 10 by odds ratio)
- Statistical summaries (mean/median odds ratios, total observations)

**Example strongest relationship:** F00 (Dementia) ↔ G30 (Alzheimer's): OR = 60,143

## API Usage

You can also use the pipeline programmatically:

```python
from scripts.data_cleaning import process_all_matrices

edges, metadata, report = process_all_matrices(
    data_dir='Data',
    output_dir='data/processed',
    min_odds_ratio=1.5,
    min_count=100,
    translate=True
)

# Access results
print(f"Total pairs: {len(edges)}")
print(f"Unique diseases: {len(metadata)}")
print(report)
```

## Module Functions

### Core Functions (data_cleaning.py)

- `process_all_matrices()`: Main processing function
- `load_adjacency_matrix()`: Load space-separated CSV matrices
- `extract_pvalues_from_csv()`: Extract p-values and counts from exported CSV files (recommended)
- `extract_pvalues_from_rds()`: Extract p-values and counts from R .rds files (deprecated - pyreadr cannot read these files)
- `matrix_to_edgelist()`: Convert matrix to edge-list DataFrame
- `get_icd_chapter()`: Map ICD-10 codes to chapters
- `translate_german_to_english()`: Translate disease names
- `generate_metadata()`: Create disease metadata
- `generate_processing_report()`: Create validation report

### Export Script (scripts/export_contingency_tables.R)

R script that exports contingency table RDS files to CSV format:
- Processes 6 RDS files (ICD/Blocks/Chronic × Male/Female)
- Generates 14 stratifications per file (6 year periods + 8 age groups)
- Exports 3 matrices per stratification (p-values, counts, odds ratios)
- Total: 252 CSV files (6 × 14 × 3)
- Uses Mantel-Haenszel test with Fisher's exact test fallback

## Stratifications

The pipeline processes 82 stratified matrices:

| Factor | Values | Count |
|--------|--------|-------|
| Sex | Male, Female | 2 |
| Granularity | ICD, Blocks, Chronic | 3 |
| Years | 2003-04, 2005-06, 2007-08, 2009-10, 2011-12, 2013-14 | 6 |
| Age Groups | 1-8 (0-9, 10-19, ..., 70+) | 8 |

**Total: 2 × 3 × (6 year matrices + 8 age matrices) = 84 - 2 (missing Both sex) = 82**

## Filters Applied

- **Odds Ratio**: ≥ 1.5 (configurable with --min-or)
- **Patient Count**: ≥ 100 (configurable with --min-count)
- **P-value**: Retained but not filtered (for information only)

## Requirements

- Python 3.8+
- pandas ≥ 2.0.0
- numpy ≥ 1.24.0
- pyreadr ≥ 0.5.0 (for R .rds files)
- deep-translator ≥ 1.11.0 (optional, for translation)

## Notes

- **Required Step**: Always run `export_contingency_tables.R` before the Python pipeline
- **Export Time**: The R export script takes ~5-10 minutes for Blocks/Chronic, but 30-60 minutes for ICD files (especially ICD Male which is ~107MB with 1080×1080 matrices)
- **Missing P-values**: You may see "P-values available: X / Y" in the report. This occurs when:
  1. **Export incomplete**: The R export script hasn't finished processing all files yet. The script processes files sequentially, and ICD Male (the largest) is processed last. Check progress with: `ls Data/Data/2.ContingencyTables/exported/ | grep ICD_ContingencyTables_Male | wc -l` (should be 42 when complete)
  2. **Statistical test failures**: The R script attempts Mantel-Haenszel test first, then falls back to Fisher's exact test. If both fail due to insufficient data (< 2 rows after filtering), p-value is set to NA
  3. **Insufficient contingency table data**: Disease pairs with limited co-occurrence data cannot be statistically tested
- **Rerun Export**: If the export was interrupted, simply run it again - it will process only missing files
- **Expected Completion**: All 252 CSV files (6 RDS × 14 stratifications × 3 matrices) should be generated
- Translation requires internet connection (uses Google Translate via deep-translator)
- Processing time depends on the number of matrices and system performance
- The 1080×1080 ICD matrices are the largest and take longest to process
- Exported CSV files are required for p-values and counts; without them, these fields will be NULL
- The RDS files contain complex 5D arrays that pyreadr cannot read directly
- The export script only needs to be run once (or when RDS files change)

## Author

Claude Code

## License

MIT License (or specify your project's license)
