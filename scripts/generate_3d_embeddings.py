"""
Module 1.4: Generate 3D Coordinates from Adjacency Matrices

This module generates 3D embeddings from disease adjacency matrices using multiple
dimensionality reduction techniques. Supports NetworkX spring layout (force-directed),
t-SNE (t-Distributed Stochastic Neighbor Embedding), and UMAP (Uniform Manifold
Approximation and Projection).

The embeddings preserve the network structure of disease comorbidity relationships
for visualization and further analysis. Disease codes are extracted from the
matrix rows/columns and validated against existing metadata when available.

Usage:
    python scripts/generate_3d_embeddings.py
    python scripts/generate_3d_embeddings.py --method umap --data-dir Data
    python scripts/generate_3d_embeddings.py --method tsne --output-dir data/processed

Author: Agent 3 (3D Embeddings Module)
Date: January 2026
"""

import argparse
import logging
import sys
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

# Set random seed for reproducibility across all embedding methods
RANDOM_SEED = 42

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)],
)
logger = logging.getLogger(__name__)


def load_adjacency_matrix(
    adj_dir: str,
    sex: str = "Male",
    year: str = "2013-2014",
    granularity: str = "ICD",
) -> Tuple[np.ndarray, List[str]]:
    """
    Load adjacency matrix for specified stratum.

    Loads space-separated adjacency matrix files generated by the R pipeline.
    The matrix represents disease comorbidity relationships with odds ratios.

    Args:
        adj_dir: Directory containing adjacency matrices
        sex: 'Male' or 'Female' (default: 'Male')
        year: Year period (e.g., '2013-2014', default: '2013-2014')
        granularity: Granularity level ('ICD', 'Blocks', 'Chronic')

    Returns:
        Tuple of (adjacency_matrix, disease_codes)
        - adjacency_matrix: numpy array (n x n) with odds ratios
        - disease_codes: list of disease identifiers

    Raises:
        FileNotFoundError: If the adjacency matrix file does not exist
        ValueError: If the matrix cannot be loaded

    Security Note:
        Uses np.loadtxt which validates numeric input only
    """
    filename = f"Adj_Matrix_{sex}_{granularity}_year_{year}.csv"
    filepath = Path(adj_dir) / filename

    if not filepath.exists():
        raise FileNotFoundError(f"Adjacency matrix not found: {filepath}")

    try:
        # Load space-separated matrix
        matrix = np.loadtxt(filepath, delimiter=" ")
        logger.info(f"Loaded matrix: {matrix.shape}")

        # Ensure matrix is symmetric (average of upper and lower triangles)
        matrix = (matrix + matrix.T) / 2

        # Replace zeros and invalid values with small positive values
        # This prevents division by zero in distance calculations
        matrix = np.where(
            (matrix == 0) | np.isnan(matrix) | np.isinf(matrix), 0.001, matrix
        )

        # Generate disease codes from matrix indices
        codes = [f"CODE_{i}" for i in range(matrix.shape[0])]

        return matrix, codes

    except Exception as e:
        logger.error(f"Failed to load adjacency matrix: {e}")
        raise ValueError(f"Invalid matrix file: {filepath}") from e


def load_disease_codes(metadata_path: str) -> List[str]:
    """
    Load disease codes from existing metadata CSV.

    Args:
        metadata_path: Path to disease_metadata.csv

    Returns:
        List of disease codes in order

    Raises:
        FileNotFoundError: If metadata file does not exist
    """
    if not Path(metadata_path).exists():
        raise FileNotFoundError(f"Metadata file not found: {metadata_path}")

    df = pd.read_csv(metadata_path)

    # Filter to ICD granularity only (1080 codes)
    if "granularity" in df.columns:
        icd_df = df[df["granularity"] == "ICD"]
        return icd_df["code"].tolist()

    return df["code"].tolist()


def embed_spring_layout(
    adj_matrix: np.ndarray,
    k: float = 0.5,
    iterations: int = 100,
    seed: int = RANDOM_SEED,
) -> np.ndarray:
    """
    Generate 3D coordinates using NetworkX force-directed spring layout.

    Uses force-directed placement algorithm where nodes repel each other like
    springs, with edge weights determining attraction strength. Good for
    visualizing network topology and community structure.

    Args:
        adj_matrix: Adjacency matrix (n x n) with similarity weights
        k: Optimal distance between nodes (default: 0.5)
           Smaller values = tighter clusters, larger = more spread
        iterations: Number of iterations for convergence (default: 100)
        seed: Random seed for reproducibility (default: RANDOM_SEED)

    Returns:
        Coordinates array (n x 3) with 3D positions

    References:
        Fruchterman, T.M.J. and Reingold, E.M. (1991). Graph drawing by
        force-directed placement. Software: Practice and Experience.

    Security Note:
        No external network calls. Only processes provided matrix data.
    """
    import networkx as nx

    logger.info(f"Computing spring layout (k={k}, iterations={iterations})...")

    # Create weighted graph from adjacency matrix
    G = nx.from_numpy_array(adj_matrix)

    # Compute 3D spring layout with fixed seed for reproducibility
    pos = nx.spring_layout(G, dim=3, k=k, iterations=iterations, seed=seed)

    # Convert dictionary to numpy array
    coords = np.array([pos[i] for i in range(len(pos))])

    logger.info(f"Spring layout complete: {coords.shape}")
    return coords


def embed_tsne(
    adj_matrix: np.ndarray,
    perplexity: int = 30,
    n_iter: int = 1000,
    learning_rate: str = "auto",
    random_state: int = RANDOM_SEED,
) -> np.ndarray:
    """
    Generate 3D coordinates using t-SNE dimensionality reduction.

    t-SNE (t-Distributed Stochastic Neighbor Embedding) preserves local
    neighborhoods by converting similarities to probabilities. Excellent
    for revealing clusters but can be slower than UMAP.

    Args:
        adj_matrix: Adjacency matrix (n x n) with similarity weights
        perplexity: Effective number of neighbors (default: 30)
                    Higher values = more global structure, range 5-50
        n_iter: Number of optimization iterations (default: 1000)
        learning_rate: Learning rate strategy (default: 'auto')
        random_state: Random seed for reproducibility (default: RANDOM_SEED)

    Returns:
        Coordinates array (n x 3) with 3D positions

    References:
        van der Maaten, L. and Hinton, G. (2008). Visualizing data using t-SNE.
        Journal of Machine Learning Research.

    Security Note:
        Uses sklearn's validated implementation. No external data access.
    """
    from sklearn.manifold import TSNE
    from sklearn.preprocessing import StandardScaler

    logger.info(f"Computing t-SNE (perplexity={perplexity}, iterations={n_iter})...")

    # Normalize matrix for better t-SNE performance
    scaler = StandardScaler()
    adj_normalized = scaler.fit_transform(adj_matrix)

    # Apply t-SNE with PCA initialization for stability
    tsne = TSNE(
        n_components=3,
        perplexity=perplexity,
        max_iter=n_iter,
        learning_rate=learning_rate,
        random_state=random_state,
        init="pca",
        verbose=0,
    )

    coords = tsne.fit_transform(adj_normalized)

    logger.info(f"t-SNE complete: {coords.shape}")
    return coords


def embed_umap(
    adj_matrix: np.ndarray,
    n_neighbors: int = 15,
    min_dist: float = 0.1,
    metric: str = "precomputed",
    random_state: int = RANDOM_SEED,
) -> np.ndarray:
    """
    Generate 3D coordinates using UMAP dimensionality reduction.

    UMAP (Uniform Manifold Approximation and Projection) balances local
    and global structure preservation. Generally faster than t-SNE and
    better at preserving global topology. Recommended for disease networks.

    Args:
        adj_matrix: Adjacency matrix (n x n) with similarity weights
        n_neighbors: Number of neighbors for local structure (default: 15)
                     Higher values = more global structure
        min_dist: Minimum distance between points (default: 0.1)
                  Smaller = tighter clusters, larger = more dispersed
        metric: Distance metric, 'precomputed' for distance matrices (default)
        random_state: Random seed for reproducibility (default: RANDOM_SEED)

    Returns:
        Coordinates array (n x 3) with 3D positions

    References:
        McInnes, L., Healy, J. and Melville, J. (2018). UMAP: Uniform Manifold
        Approximation and Projection for Dimension Reduction.

    Security Note:
        No external network calls. Processes only provided matrix data.
    """
    from umap import UMAP

    logger.info(f"Computing UMAP (n_neighbors={n_neighbors}, min_dist={min_dist})...")

    # Convert similarity matrix to distance matrix
    # Using inverse similarity: dist = 1 / (similarity + epsilon)
    # Adding small epsilon to prevent division by zero
    epsilon = 0.001
    dist_matrix = 1.0 / (adj_matrix + epsilon)

    # Ensure distance matrix is symmetric
    dist_matrix = (dist_matrix + dist_matrix.T) / 2

    # Apply UMAP with precomputed distances
    embedder = UMAP(
        n_components=3,
        n_neighbors=n_neighbors,
        min_dist=min_dist,
        metric=metric,
        random_state=random_state,
        verbose=False,
    )

    coords = embedder.fit_transform(dist_matrix)

    logger.info(f"UMAP complete: {coords.shape}")
    return coords


def normalize_coordinates(
    coords: np.ndarray,
    range_min: float = -1.0,
    range_max: float = 1.0,
) -> np.ndarray:
    """
    Normalize coordinates to specified range using min-max scaling.

    Args:
        coords: Input coordinates array (n x d)
        range_min: Minimum value for output range (default: -1.0)
        range_max: Maximum value for output range (default: 1.0)

    Returns:
        Normalized coordinates array

    Security Note:
        Simple mathematical operation on provided data only.
    """
    from sklearn.preprocessing import MinMaxScaler

    scaler = MinMaxScaler(feature_range=(range_min, range_max))
    return scaler.fit_transform(coords)


def validate_embedding(
    coords: np.ndarray,
    disease_codes: List[str],
) -> Dict:
    """
    Validate embedding quality by measuring chapter clustering.

    Calculates the ratio of between-chapter distances to within-chapter
    distances. Higher ratios indicate better clustering by ICD chapter.

    Args:
        coords: 3D coordinates array (n x 3)
        disease_codes: List of disease ICD codes

    Returns:
        Dictionary containing validation metrics:
        - num_points: Number of diseases embedded
        - coord_range_x/y/z: Coordinate bounds
        - avg_within_chapter_distance: Mean distance within same chapter
        - avg_between_chapter_distance: Mean distance across chapters
        - clustering_quality_ratio: Ratio of between/within distances
        - passes_quality_threshold: Whether ratio > 1.5

    Note:
        ICD chapters are extracted from the first character of each code.
        A ratio > 1.5 indicates diseases in the same chapter cluster together.
    """
    from scipy.spatial.distance import pdist, squareform

    # Compute pairwise Euclidean distances in 3D space
    dist_matrix = squareform(pdist(coords, metric="euclidean"))

    # Extract ICD chapters from first character of codes
    chapters = []
    for code in disease_codes:
        if code and len(code) > 0:
            chapters.append(code[0].upper())
        else:
            chapters.append("X")  # Unknown chapter

    unique_chapters = list(set(chapters))
    logger.info(f"Found {len(unique_chapters)} unique ICD chapters")

    # Calculate average within-chapter and between-chapter distances
    within_dists = []
    between_dists = []

    n = len(coords)
    # Only validate on diseases with known chapters (skip padded CODE_X entries)
    valid_indices = [
        i
        for i, ch in enumerate(chapters)
        if ch != "X" and not disease_codes[i].startswith("CODE_")
    ]
    logger.info(
        f"Validating on {len(valid_indices)} diseases with known chapter assignments"
    )

    for idx_i, i in enumerate(valid_indices):
        for idx_j, j in enumerate(valid_indices):
            if i < j:  # Only process upper triangle
                dist = dist_matrix[i, j]
                if chapters[i] == chapters[j]:
                    within_dists.append(dist)
                else:
                    between_dists.append(dist)

    avg_within = np.mean(within_dists) if within_dists else 0.0
    avg_between = np.mean(between_dists) if between_dists else 0.0
    clustering_ratio = avg_between / avg_within if avg_within > 0 else 0.0

    metrics = {
        "num_points": len(coords),
        "coord_range_x": (float(coords[:, 0].min()), float(coords[:, 0].max())),
        "coord_range_y": (float(coords[:, 1].min()), float(coords[:, 1].max())),
        "coord_range_z": (float(coords[:, 2].min()), float(coords[:, 2].max())),
        "avg_within_chapter_distance": float(avg_within),
        "avg_between_chapter_distance": float(avg_between),
        "clustering_quality_ratio": float(clustering_ratio),
        "passes_quality_threshold": clustering_ratio > 1.5,
    }

    return metrics


def visualize_embedding(
    coords: np.ndarray,
    disease_codes: List[str],
    output_path: str,
    dpi: int = 300,
) -> None:
    """
    Generate 3D visualization of embeddings colored by ICD chapter.

    Creates a scatter plot in 3D space with diseases colored by their
    ICD chapter (first character of disease code).

    Args:
        coords: 3D coordinates array (n x 3)
        disease_codes: List of disease ICD codes
        output_path: Path to save PNG file
        dpi: Image resolution (default: 300)

    Security Note:
        No external data access. Saves to specified local path only.
    """
    import matplotlib.pyplot as plt
    from mpl_toolkits.mplot3d import Axes3D  # noqa: F401

    # Extract ICD chapters from codes
    chapters = []
    for code in disease_codes:
        if code and len(code) > 0:
            chapters.append(code[0].upper())
        else:
            chapters.append("X")

    unique_chapters = sorted(set(chapters))

    # Create color mapping
    colormap = plt.cm.tab20
    colors = colormap(np.linspace(0, 1, len(unique_chapters)))
    chapter_colors = {ch: colors[i] for i, ch in enumerate(unique_chapters)}

    # Create figure
    fig = plt.figure(figsize=(14, 10))
    ax = fig.add_subplot(111, projection="3d")

    # Plot each chapter separately for legend
    for chapter in unique_chapters:
        mask = np.array([ch == chapter for ch in chapters])
        indices = np.where(mask)[0]

        ax.scatter(
            coords[indices, 0],
            coords[indices, 1],
            coords[indices, 2],
            c=[chapter_colors[chapter]],
            label=f"Chapter {chapter}",
            alpha=0.6,
            s=20,
        )

    ax.set_xlabel("X")
    ax.set_ylabel("Y")
    ax.set_zlabel("Z")
    ax.set_title("3D Disease Network Embedding (Colored by ICD Chapter)")

    # Place legend outside plot
    ax.legend(
        loc="upper left",
        bbox_to_anchor=(1.05, 1),
        fontsize=8,
        title="ICD Chapter",
    )

    plt.tight_layout()

    # Save to file
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_path, dpi=dpi, bbox_inches="tight")
    plt.close()

    logger.info(f"Saved visualization: {output_path}")


def generate_quality_report(
    metrics: Dict,
    method: str,
    output_path: str,
) -> None:
    """
    Generate text report of embedding quality metrics.

    Args:
        metrics: Validation metrics dictionary
        method: Embedding method name ('umap', 'tsne', or 'spring')
        output_path: Path to save report file

    Security Note:
        Writes to specified local path only.
    """
    report_lines = [
        "3D EMBEDDING QUALITY REPORT",
        "=" * 60,
        "",
        f"Method: {method}",
        f"Random Seed: {RANDOM_SEED}",
        "",
        f"Number of diseases: {metrics['num_points']}",
        "",
        "Coordinate Ranges:",
        f"  X: {metrics['coord_range_x'][0]:.3f} to {metrics['coord_range_x'][1]:.3f}",
        f"  Y: {metrics['coord_range_y'][0]:.3f} to {metrics['coord_range_y'][1]:.3f}",
        f"  Z: {metrics['coord_range_z'][0]:.3f} to {metrics['coord_range_z'][1]:.3f}",
        "",
        "Clustering Quality:",
        f"  Avg within-chapter distance: {metrics['avg_within_chapter_distance']:.3f}",
        f"  Avg between-chapter distance: {metrics['avg_between_chapter_distance']:.3f}",
        f"  Clustering ratio: {metrics['clustering_quality_ratio']:.2f}x",
        "",
        f"Quality Threshold (>1.5): {'PASS' if metrics['passes_quality_threshold'] else 'FAIL'}",
        "",
        "=" * 60,
    ]

    # Write report
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w") as f:
        f.write("\n".join(report_lines))

    logger.info(f"Saved quality report: {output_path}")


def main(
    data_dir: str = "Data",
    output_dir: str = "data/processed",
    method: str = "umap",
    sex: str = "Male",
    year: str = "2013-2014",
) -> Tuple[Optional[pd.DataFrame], Optional[Dict]]:
    """
    Main execution function for 3D embedding generation.

    Loads adjacency matrix, generates 3D coordinates using specified method,
    validates quality, and saves outputs.

    Args:
        data_dir: Root data directory (default: 'Data')
        output_dir: Output directory for results (default: 'data/processed')
        method: Embedding method ('spring', 'tsne', 'umap', default: 'umap')
        sex: Patient sex stratification ('Male' or 'Female')
        year: Year period for data

    Returns:
        Tuple of (vectors_df, metrics) or (None, None) on failure

    Output Files:
        - disease_vectors_3d.csv: 3D coordinates with disease codes
        - 3d_embedding_visualization.png: 3D scatter plot
        - embedding_quality_report.txt: Validation metrics
        - .embeddings_done: Completion marker file
    """
    # Setup paths
    adj_dir = Path(data_dir) / "Data" / "3.AdjacencyMatrices"
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    validation_dir = Path(data_dir) / "validation"
    validation_dir.mkdir(parents=True, exist_ok=True)

    try:
        # Load adjacency matrix
        logger.info(f"Loading adjacency matrix ({sex}, {year})...")
        adj_matrix, codes = load_adjacency_matrix(str(adj_dir), sex, year)

        # Try to load actual disease codes from metadata if available
        # Check multiple possible locations for the metadata file
        metadata_paths = [
            Path(output_dir) / "disease_metadata.csv",
            Path("data/processed/disease_metadata.csv"),
            Path("Data/processed/disease_metadata.csv"),
        ]

        codes_loaded = False
        for metadata_path in metadata_paths:
            if metadata_path.exists():
                try:
                    codes = load_disease_codes(str(metadata_path))
                    logger.info(
                        f"Loaded {len(codes)} disease codes from metadata: {metadata_path}"
                    )
                    # Pad codes if metadata has fewer entries than matrix
                    if len(codes) < adj_matrix.shape[0]:
                        logger.warning(
                            f"Metadata has {len(codes)} codes but matrix has {adj_matrix.shape[0]} rows. "
                            f"Padding with placeholder codes."
                        )
                        for i in range(len(codes), adj_matrix.shape[0]):
                            codes.append(f"CODE_{i}")
                    codes_loaded = True
                    break
                except Exception as e:
                    logger.warning(f"Could not load metadata from {metadata_path}: {e}")

        if not codes_loaded:
            logger.warning(
                "Could not load metadata codes from any location, using default CODE_X format"
            )

        # Generate embedding based on method
        logger.info(f"Generating 3D embedding using {method}...")

        if method == "spring":
            coords = embed_spring_layout(adj_matrix)
        elif method == "tsne":
            coords = embed_tsne(adj_matrix)
        elif method == "umap":
            coords = embed_umap(adj_matrix)
        else:
            raise ValueError(f"Unknown method: {method}")

        # Normalize to [-1, 1] range
        coords = normalize_coordinates(coords)
        logger.info("Coordinates normalized to [-1, 1] range")

        # Validate embedding quality
        logger.info("Validating embedding quality...")
        metrics = validate_embedding(coords, codes)

        # Log quality metrics
        logger.info(f"Clustering ratio: {metrics['clustering_quality_ratio']:.2f}x")
        if metrics["passes_quality_threshold"]:
            logger.info("Quality check: PASS (>1.5)")
        else:
            logger.warning("Quality check: FAIL (ratio < 1.5)")

        # Save coordinates to CSV
        vectors_df = pd.DataFrame(
            {
                "icd_code": codes[: len(coords)],
                "vector_x": coords[:, 0],
                "vector_y": coords[:, 1],
                "vector_z": coords[:, 2],
            }
        )

        output_csv = output_path / "disease_vectors_3d.csv"
        vectors_df.to_csv(output_csv, index=False)
        logger.info(f"Saved disease_vectors_3d.csv: {len(vectors_df)} vectors")

        # Generate visualization
        viz_path = validation_dir / "3d_embedding_visualization.png"
        visualize_embedding(coords, codes, str(viz_path))

        # Generate quality report
        report_path = validation_dir / "embedding_quality_report.txt"
        generate_quality_report(metrics, method, str(report_path))

        # Create completion marker
        marker_file = output_path / ".embeddings_done"
        marker_file.touch()
        logger.info(f"Created completion marker: {marker_file}")

        logger.info("3D embedding generation complete!")
        return vectors_df, metrics

    except Exception as e:
        logger.error(f"Embedding generation failed: {e}")
        return None, None


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Generate 3D embeddings from disease adjacency matrices",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python scripts/generate_3d_embeddings.py
  python scripts/generate_3d_embeddings.py --method umap
  python scripts/generate_3d_embeddings.py --method tsne --data-dir /path/to/data
  python scripts/generate_3d_embeddings.py --method spring --sex Female --year 2011-2012

Methods:
  umap    - Recommended default. Fast, good global + local structure
  tsne    - Best local clustering. Slower but detailed
  spring  - Force-directed layout. Good for network visualization
        """,
    )

    parser.add_argument(
        "--data-dir",
        default="Data",
        help="Root data directory (default: Data)",
    )
    parser.add_argument(
        "--output-dir",
        default="data/processed",
        help="Output directory (default: data/processed)",
    )
    parser.add_argument(
        "--method",
        choices=["spring", "tsne", "umap"],
        default="umap",
        help="Embedding method (default: umap)",
    )
    parser.add_argument(
        "--sex",
        choices=["Male", "Female"],
        default="Male",
        help="Patient sex stratification (default: Male)",
    )
    parser.add_argument(
        "--year",
        default="2013-2014",
        help="Year period (default: 2013-2014)",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable verbose logging",
    )

    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    main(args.data_dir, args.output_dir, args.method, args.sex, args.year)
